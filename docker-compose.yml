version: '3.8'

services:
  redis-fs:
    container_name: redis_fs
    image: redis:6
    restart: always
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  api_fs:
    container_name: fastapi_app
    build: .
    restart: always
    ports:
      - "8000:8000"
    environment:
      - REDIS_HOST=redis-fs
      - REDIS_PORT=6379
    depends_on:
      - redis-fs

  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres_data:/var/lib/postgresql/data

  airflow-webserver:
    image: apache/airflow:2.9.1
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__WEBSERVER__SECRET_KEY: 5SFQFYI40xXJNByg8be1JJTZpi8srLeYIRuq_Nhb1tg
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/batch_features:/opt/airflow/batch_features
      - ./requirements.txt:/requirements.txt
    ports:
      - "8080:8080"
    command: >
      bash -c "
        pip install -r /requirements.txt &&
        airflow db upgrade &&
        airflow users create --username admin --password admin --firstname admin --lastname admin --role Admin --email admin@example.com &&
        airflow webserver --host 0.0.0.0
      "

  airflow-scheduler:
    image: apache/airflow:2.9.1
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__WEBSERVER__SECRET_KEY: 5SFQFYI40xXJNByg8be1JJTZpi8srLeYIRuq_Nhb1tg
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/batch_features:/opt/airflow/batch_features
      - ./requirements.txt:/requirements.txt
    command: >
      bash -c "
        pip install -r /requirements.txt &&
        airflow scheduler
      "
      

volumes:
  postgres_data:
  redis_data:
